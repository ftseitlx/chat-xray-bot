services:
  - type: web
    name: chat-xray-bot
    env: docker
    plan: free
    healthCheckPath: /health
    port: 8080
    dockerfilePath: Dockerfile
    envVars:
      - key: BOT_TOKEN
        sync: false
      - key: OPENAI_API_KEY
        sync: false
      - key: WEBHOOK_HOST
        fromService:
          name: chat-xray-bot
          type: web
          property: host
      - key: WEBHOOK_PATH
        value: /webhook
      - key: PORT
        value: 8080
      - key: HOST
        value: 0.0.0.0
      - key: UPLOAD_RETENTION_HOURS
        value: 1
      - key: REPORT_RETENTION_HOURS
        value: 72
      - key: ENABLE_COST_TRACKING
        value: true
      - key: USE_LOCAL_LLM
        value: "true"
      - key: OLLAMA_URL
        value: http://llama2-ollama:11434
      - key: OLLAMA_MODEL
        value: llama2:7b-chat

  - type: private_service
    name: llama2-ollama
    env: docker
    plan: starter  # 2 GB RAM, достаточно для llama2:7b-chat Q4
    dockerfilePath: Dockerfile.ollama
    port: 11434
    autoDeploy: false
    disk:
      name: ollama-cache
      mountPath: /root/.ollama
      sizeGB: 10 