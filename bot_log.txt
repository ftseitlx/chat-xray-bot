2025-05-13 15:15:22,624 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-05-13 15:15:22,624 - apscheduler.scheduler - INFO - Adding job tentatively -- it will be properly scheduled when the scheduler starts
2025-05-13 15:15:22,624 - apscheduler.scheduler - INFO - Added job "clean_old_uploads" to job store "default"
2025-05-13 15:15:22,624 - apscheduler.scheduler - INFO - Added job "clean_old_reports" to job store "default"
2025-05-13 15:15:22,624 - apscheduler.scheduler - INFO - Scheduler started
2025-05-13 15:15:23,384 - aiogram.dispatcher - INFO - Start polling
2025-05-13 15:15:23,685 - aiogram.dispatcher - INFO - Run polling for bot @emotionalanalbot id=7216011927 - 'emotionalanal'
2025-05-13 15:16:07,439 - app.services.chunker - INFO - Extracted 2743 messages from the chat file.
2025-05-13 15:16:07,439 - app.services.chunker - WARNING - Very large chat detected (2743 messages). Using aggressive chunking.
2025-05-13 15:16:07,442 - app.services.chunker - INFO - Split chat into 183 chunks.
2025-05-13 15:16:07,666 - app.services.llm_primary - INFO - Processing chunk 1/183
2025-05-13 15:16:14,328 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:14,335 - app.services.llm_primary - INFO - Processing chunk 2/183
2025-05-13 15:16:16,745 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:16,747 - app.services.llm_primary - INFO - Processing chunk 3/183
2025-05-13 15:16:18,941 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:18,946 - app.services.llm_primary - INFO - Processing chunk 4/183
2025-05-13 15:16:20,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:20,777 - app.services.llm_primary - INFO - Processing chunk 5/183
2025-05-13 15:16:22,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:22,932 - app.services.llm_primary - INFO - Processing chunk 6/183
2025-05-13 15:16:22,932 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:16:25,892 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:25,894 - app.services.llm_primary - INFO - Processing chunk 7/183
2025-05-13 15:16:27,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:27,443 - app.services.llm_primary - INFO - Processing chunk 8/183
2025-05-13 15:16:29,005 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:29,007 - app.services.llm_primary - INFO - Processing chunk 9/183
2025-05-13 15:16:34,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:34,095 - app.services.llm_primary - INFO - Processing chunk 10/183
2025-05-13 15:16:36,461 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:36,465 - app.services.llm_primary - INFO - Processing chunk 11/183
2025-05-13 15:16:36,465 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:16:41,120 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:41,125 - app.services.llm_primary - INFO - Processing chunk 12/183
2025-05-13 15:16:49,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:49,167 - app.services.llm_primary - INFO - Processing chunk 13/183
2025-05-13 15:16:51,438 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:51,441 - app.services.llm_primary - INFO - Processing chunk 14/183
2025-05-13 15:16:53,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:53,588 - app.services.llm_primary - INFO - Processing chunk 15/183
2025-05-13 15:16:56,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:16:56,350 - app.services.llm_primary - INFO - Processing chunk 16/183
2025-05-13 15:16:56,351 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:17:01,056 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:01,059 - app.services.llm_primary - INFO - Processing chunk 17/183
2025-05-13 15:17:04,382 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:04,386 - app.services.llm_primary - INFO - Processing chunk 18/183
2025-05-13 15:17:07,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:07,606 - app.services.llm_primary - INFO - Processing chunk 19/183
2025-05-13 15:17:08,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:08,947 - app.services.llm_primary - INFO - Processing chunk 20/183
2025-05-13 15:17:11,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:11,248 - app.services.llm_primary - INFO - Processing chunk 21/183
2025-05-13 15:17:11,249 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:17:18,703 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:18,707 - app.services.llm_primary - INFO - Processing chunk 22/183
2025-05-13 15:17:20,583 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:20,586 - app.services.llm_primary - INFO - Processing chunk 23/183
2025-05-13 15:17:22,765 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:22,771 - app.services.llm_primary - INFO - Processing chunk 24/183
2025-05-13 15:17:24,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:24,789 - app.services.llm_primary - INFO - Processing chunk 25/183
2025-05-13 15:17:26,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:26,930 - app.services.llm_primary - INFO - Processing chunk 26/183
2025-05-13 15:17:26,930 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:17:30,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:30,876 - app.services.llm_primary - INFO - Processing chunk 27/183
2025-05-13 15:17:32,613 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:32,615 - app.services.llm_primary - INFO - Processing chunk 28/183
2025-05-13 15:17:35,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:35,067 - app.services.llm_primary - INFO - Processing chunk 29/183
2025-05-13 15:17:37,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:37,242 - app.services.llm_primary - INFO - Processing chunk 30/183
2025-05-13 15:17:40,270 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:40,273 - app.services.llm_primary - INFO - Processing chunk 31/183
2025-05-13 15:17:40,273 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:17:43,235 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:43,244 - app.services.llm_primary - INFO - Processing chunk 32/183
2025-05-13 15:17:46,335 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:46,338 - app.services.llm_primary - INFO - Processing chunk 33/183
2025-05-13 15:17:48,483 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:48,488 - app.services.llm_primary - INFO - Processing chunk 34/183
2025-05-13 15:17:50,870 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:50,875 - app.services.llm_primary - INFO - Processing chunk 35/183
2025-05-13 15:17:51,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:51,870 - app.services.llm_primary - INFO - Processing chunk 36/183
2025-05-13 15:17:51,870 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:17:55,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:17:55,132 - app.services.llm_primary - INFO - Processing chunk 37/183
2025-05-13 15:18:04,744 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:04,749 - app.services.llm_primary - INFO - Processing chunk 38/183
2025-05-13 15:18:06,484 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:06,495 - app.services.llm_primary - INFO - Processing chunk 39/183
2025-05-13 15:18:08,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:08,349 - app.services.llm_primary - INFO - Processing chunk 40/183
2025-05-13 15:18:10,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:10,187 - app.services.llm_primary - INFO - Processing chunk 41/183
2025-05-13 15:18:10,187 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:18:12,625 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:12,629 - app.services.llm_primary - INFO - Processing chunk 42/183
2025-05-13 15:18:14,299 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:14,302 - app.services.llm_primary - INFO - Processing chunk 43/183
2025-05-13 15:18:16,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:16,928 - app.services.llm_primary - INFO - Processing chunk 44/183
2025-05-13 15:18:17,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:17,894 - app.services.llm_primary - INFO - Processing chunk 45/183
2025-05-13 15:18:20,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:20,579 - app.services.llm_primary - INFO - Processing chunk 46/183
2025-05-13 15:18:20,579 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:18:23,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:23,250 - app.services.llm_primary - INFO - Processing chunk 47/183
2025-05-13 15:18:26,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:26,360 - app.services.llm_primary - INFO - Processing chunk 48/183
2025-05-13 15:18:28,363 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:28,367 - app.services.llm_primary - INFO - Processing chunk 49/183
2025-05-13 15:18:30,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:30,372 - app.services.llm_primary - INFO - Processing chunk 50/183
2025-05-13 15:18:32,311 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:32,312 - app.services.llm_primary - INFO - Processing chunk 51/183
2025-05-13 15:18:32,312 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:18:34,669 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:34,672 - app.services.llm_primary - INFO - Processing chunk 52/183
2025-05-13 15:18:37,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:37,041 - app.services.llm_primary - INFO - Processing chunk 53/183
2025-05-13 15:18:39,298 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:39,300 - app.services.llm_primary - INFO - Processing chunk 54/183
2025-05-13 15:18:40,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:40,364 - app.services.llm_primary - INFO - Processing chunk 55/183
2025-05-13 15:18:42,269 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:42,272 - app.services.llm_primary - INFO - Processing chunk 56/183
2025-05-13 15:18:42,273 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:18:46,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:46,141 - app.services.llm_primary - INFO - Processing chunk 57/183
2025-05-13 15:18:54,968 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:54,973 - app.services.llm_primary - INFO - Processing chunk 58/183
2025-05-13 15:18:58,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:18:58,442 - app.services.llm_primary - INFO - Processing chunk 59/183
2025-05-13 15:19:00,153 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:00,154 - app.services.llm_primary - INFO - Processing chunk 60/183
2025-05-13 15:19:02,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:02,624 - app.services.llm_primary - INFO - Processing chunk 61/183
2025-05-13 15:19:02,624 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:19:06,550 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:06,552 - app.services.llm_primary - INFO - Processing chunk 62/183
2025-05-13 15:19:12,147 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:12,151 - app.services.llm_primary - INFO - Processing chunk 63/183
2025-05-13 15:19:14,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:14,178 - app.services.llm_primary - INFO - Processing chunk 64/183
2025-05-13 15:19:18,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:18,814 - app.services.llm_primary - INFO - Processing chunk 65/183
2025-05-13 15:19:20,585 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:20,588 - app.services.llm_primary - INFO - Processing chunk 66/183
2025-05-13 15:19:20,588 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:19:23,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:23,631 - app.services.llm_primary - INFO - Processing chunk 67/183
2025-05-13 15:19:26,597 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:26,604 - app.services.llm_primary - INFO - Processing chunk 68/183
2025-05-13 15:19:28,840 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:28,851 - app.services.llm_primary - INFO - Processing chunk 69/183
2025-05-13 15:19:30,899 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:30,905 - app.services.llm_primary - INFO - Processing chunk 70/183
2025-05-13 15:19:32,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:32,379 - app.services.llm_primary - INFO - Processing chunk 71/183
2025-05-13 15:19:32,379 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:19:35,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:35,499 - app.services.llm_primary - INFO - Processing chunk 72/183
2025-05-13 15:19:37,271 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:37,275 - app.services.llm_primary - INFO - Processing chunk 73/183
2025-05-13 15:19:38,831 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:38,843 - app.services.llm_primary - INFO - Processing chunk 74/183
2025-05-13 15:19:41,033 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:41,036 - app.services.llm_primary - INFO - Processing chunk 75/183
2025-05-13 15:19:43,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:43,016 - app.services.llm_primary - INFO - Processing chunk 76/183
2025-05-13 15:19:43,016 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:19:46,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:46,605 - app.services.llm_primary - INFO - Processing chunk 77/183
2025-05-13 15:19:49,278 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:49,281 - app.services.llm_primary - INFO - Processing chunk 78/183
2025-05-13 15:19:52,406 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:19:52,411 - app.services.llm_primary - INFO - Processing chunk 79/183
2025-05-13 15:20:18,132 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:18,138 - app.services.llm_primary - INFO - Processing chunk 80/183
2025-05-13 15:20:22,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:22,976 - app.services.llm_primary - INFO - Processing chunk 81/183
2025-05-13 15:20:22,976 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:20:25,595 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:25,598 - app.services.llm_primary - INFO - Processing chunk 82/183
2025-05-13 15:20:27,631 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:27,632 - app.services.llm_primary - INFO - Processing chunk 83/183
2025-05-13 15:20:30,105 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:30,107 - app.services.llm_primary - INFO - Processing chunk 84/183
2025-05-13 15:20:31,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:31,823 - app.services.llm_primary - INFO - Processing chunk 85/183
2025-05-13 15:20:33,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:33,459 - app.services.llm_primary - INFO - Processing chunk 86/183
2025-05-13 15:20:33,459 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:20:40,222 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:40,226 - app.services.llm_primary - INFO - Processing chunk 87/183
2025-05-13 15:20:41,990 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:41,994 - app.services.llm_primary - INFO - Processing chunk 88/183
2025-05-13 15:20:44,136 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:44,139 - app.services.llm_primary - INFO - Processing chunk 89/183
2025-05-13 15:20:46,453 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:46,456 - app.services.llm_primary - INFO - Processing chunk 90/183
2025-05-13 15:20:50,094 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:50,098 - app.services.llm_primary - INFO - Processing chunk 91/183
2025-05-13 15:20:50,099 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:20:53,288 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:53,290 - app.services.llm_primary - INFO - Processing chunk 92/183
2025-05-13 15:20:57,920 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:20:57,928 - app.services.llm_primary - INFO - Processing chunk 93/183
2025-05-13 15:21:01,762 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:01,766 - app.services.llm_primary - INFO - Processing chunk 94/183
2025-05-13 15:21:04,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:04,452 - app.services.llm_primary - INFO - Processing chunk 95/183
2025-05-13 15:21:06,571 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:06,574 - app.services.llm_primary - INFO - Processing chunk 96/183
2025-05-13 15:21:06,575 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:21:09,333 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:09,340 - app.services.llm_primary - INFO - Processing chunk 97/183
2025-05-13 15:21:12,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:12,806 - app.services.llm_primary - INFO - Processing chunk 98/183
2025-05-13 15:21:15,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:15,340 - app.services.llm_primary - INFO - Processing chunk 99/183
2025-05-13 15:21:18,478 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:18,481 - app.services.llm_primary - INFO - Processing chunk 100/183
2025-05-13 15:21:20,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:20,030 - app.services.llm_primary - INFO - Processing chunk 101/183
2025-05-13 15:21:20,030 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:21:23,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:23,482 - app.services.llm_primary - INFO - Processing chunk 102/183
2025-05-13 15:21:25,254 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:25,255 - app.services.llm_primary - INFO - Processing chunk 103/183
2025-05-13 15:21:27,386 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:27,391 - app.services.llm_primary - INFO - Processing chunk 104/183
2025-05-13 15:21:29,725 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:29,732 - app.services.llm_primary - INFO - Processing chunk 105/183
2025-05-13 15:21:32,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:32,295 - app.services.llm_primary - INFO - Processing chunk 106/183
2025-05-13 15:21:32,295 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:21:36,508 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:36,515 - app.services.llm_primary - INFO - Processing chunk 107/183
2025-05-13 15:21:38,548 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:38,554 - app.services.llm_primary - INFO - Processing chunk 108/183
2025-05-13 15:21:40,533 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:40,540 - app.services.llm_primary - INFO - Processing chunk 109/183
2025-05-13 15:21:42,432 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:42,435 - app.services.llm_primary - INFO - Processing chunk 110/183
2025-05-13 15:21:46,605 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:46,612 - app.services.llm_primary - INFO - Processing chunk 111/183
2025-05-13 15:21:46,613 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:21:48,933 - aiogram.event - INFO - Update id=26413146 is not handled. Duration 1 ms by bot id=7216011927
2025-05-13 15:21:51,460 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:51,467 - app.services.llm_primary - INFO - Processing chunk 112/183
2025-05-13 15:21:53,751 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:53,754 - app.services.llm_primary - INFO - Processing chunk 113/183
2025-05-13 15:21:55,472 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:21:55,480 - app.services.llm_primary - INFO - Processing chunk 114/183
2025-05-13 15:22:30,355 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:30,551 - app.services.llm_primary - INFO - Processing chunk 115/183
2025-05-13 15:22:32,537 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:32,542 - app.services.llm_primary - INFO - Processing chunk 116/183
2025-05-13 15:22:32,542 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:22:42,013 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:42,015 - app.services.llm_primary - INFO - Processing chunk 117/183
2025-05-13 15:22:44,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:44,467 - app.services.llm_primary - INFO - Processing chunk 118/183
2025-05-13 15:22:46,758 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:46,759 - app.services.llm_primary - INFO - Processing chunk 119/183
2025-05-13 15:22:48,866 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:48,869 - app.services.llm_primary - INFO - Processing chunk 120/183
2025-05-13 15:22:53,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:53,030 - app.services.llm_primary - INFO - Processing chunk 121/183
2025-05-13 15:22:53,030 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:22:55,999 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:56,000 - app.services.llm_primary - INFO - Processing chunk 122/183
2025-05-13 15:22:57,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:22:57,885 - app.services.llm_primary - INFO - Processing chunk 123/183
2025-05-13 15:23:00,193 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:00,193 - app.services.llm_primary - INFO - Processing chunk 124/183
2025-05-13 15:23:02,662 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:02,664 - app.services.llm_primary - INFO - Processing chunk 125/183
2025-05-13 15:23:04,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:04,997 - app.services.llm_primary - INFO - Processing chunk 126/183
2025-05-13 15:23:04,997 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:23:08,063 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:08,065 - app.services.llm_primary - INFO - Processing chunk 127/183
2025-05-13 15:23:10,122 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:10,125 - app.services.llm_primary - INFO - Processing chunk 128/183
2025-05-13 15:23:11,234 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:11,238 - app.services.llm_primary - INFO - Processing chunk 129/183
2025-05-13 15:23:13,146 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:13,151 - app.services.llm_primary - INFO - Processing chunk 130/183
2025-05-13 15:23:17,980 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:17,981 - app.services.llm_primary - INFO - Processing chunk 131/183
2025-05-13 15:23:17,981 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:23:21,040 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:21,048 - app.services.llm_primary - INFO - Processing chunk 132/183
2025-05-13 15:23:23,294 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:23,296 - app.services.llm_primary - INFO - Processing chunk 133/183
2025-05-13 15:23:26,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:26,994 - app.services.llm_primary - INFO - Processing chunk 134/183
2025-05-13 15:23:28,565 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:28,569 - app.services.llm_primary - INFO - Processing chunk 135/183
2025-05-13 15:23:30,578 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:30,582 - app.services.llm_primary - INFO - Processing chunk 136/183
2025-05-13 15:23:30,583 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:23:33,986 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:23:33,987 - app.services.llm_primary - INFO - Processing chunk 137/183
2025-05-13 15:24:04,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:04,688 - app.services.llm_primary - INFO - Processing chunk 138/183
2025-05-13 15:24:07,164 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:07,169 - app.services.llm_primary - INFO - Processing chunk 139/183
2025-05-13 15:24:09,564 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:09,567 - app.services.llm_primary - INFO - Processing chunk 140/183
2025-05-13 15:24:11,716 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:11,720 - app.services.llm_primary - INFO - Processing chunk 141/183
2025-05-13 15:24:11,721 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:24:14,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:14,936 - app.services.llm_primary - INFO - Processing chunk 142/183
2025-05-13 15:24:16,621 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:16,624 - app.services.llm_primary - INFO - Processing chunk 143/183
2025-05-13 15:24:18,375 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:18,377 - app.services.llm_primary - INFO - Processing chunk 144/183
2025-05-13 15:24:20,797 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:20,805 - app.services.llm_primary - INFO - Processing chunk 145/183
2025-05-13 15:24:23,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:23,055 - app.services.llm_primary - INFO - Processing chunk 146/183
2025-05-13 15:24:23,055 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:24:26,781 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:26,785 - app.services.llm_primary - INFO - Processing chunk 147/183
2025-05-13 15:24:28,573 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:28,575 - app.services.llm_primary - INFO - Processing chunk 148/183
2025-05-13 15:24:30,933 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:30,935 - app.services.llm_primary - INFO - Processing chunk 149/183
2025-05-13 15:24:32,721 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:32,728 - app.services.llm_primary - INFO - Processing chunk 150/183
2025-05-13 15:24:35,230 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:35,232 - app.services.llm_primary - INFO - Processing chunk 151/183
2025-05-13 15:24:35,232 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:24:43,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:43,027 - app.services.llm_primary - INFO - Processing chunk 152/183
2025-05-13 15:24:46,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:24:46,399 - app.services.llm_primary - INFO - Processing chunk 153/183
2025-05-13 15:25:11,946 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:11,949 - app.services.llm_primary - INFO - Processing chunk 154/183
2025-05-13 15:25:14,648 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:14,650 - app.services.llm_primary - INFO - Processing chunk 155/183
2025-05-13 15:25:18,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:18,070 - app.services.llm_primary - INFO - Processing chunk 156/183
2025-05-13 15:25:18,070 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:25:21,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:21,006 - app.services.llm_primary - INFO - Processing chunk 157/183
2025-05-13 15:25:23,937 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:23,939 - app.services.llm_primary - INFO - Processing chunk 158/183
2025-05-13 15:25:25,819 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:25,821 - app.services.llm_primary - INFO - Processing chunk 159/183
2025-05-13 15:25:43,927 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:43,939 - app.services.llm_primary - INFO - Processing chunk 160/183
2025-05-13 15:25:46,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:46,978 - app.services.llm_primary - INFO - Processing chunk 161/183
2025-05-13 15:25:46,978 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:25:50,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:50,510 - app.services.llm_primary - INFO - Processing chunk 162/183
2025-05-13 15:25:53,774 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:53,775 - app.services.llm_primary - INFO - Processing chunk 163/183
2025-05-13 15:25:54,362 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:54,364 - app.services.llm_primary - INFO - Processing chunk 164/183
2025-05-13 15:25:56,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:56,352 - app.services.llm_primary - INFO - Processing chunk 165/183
2025-05-13 15:25:58,106 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:25:58,108 - app.services.llm_primary - INFO - Processing chunk 166/183
2025-05-13 15:25:58,108 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:26:00,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:00,942 - app.services.llm_primary - INFO - Processing chunk 167/183
2025-05-13 15:26:04,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:04,117 - app.services.llm_primary - INFO - Processing chunk 168/183
2025-05-13 15:26:09,008 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:09,012 - app.services.llm_primary - INFO - Processing chunk 169/183
2025-05-13 15:26:10,908 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:10,909 - app.services.llm_primary - INFO - Processing chunk 170/183
2025-05-13 15:26:12,311 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:12,313 - app.services.llm_primary - INFO - Processing chunk 171/183
2025-05-13 15:26:12,314 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:26:15,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:15,493 - app.services.llm_primary - INFO - Processing chunk 172/183
2025-05-13 15:26:17,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:17,338 - app.services.llm_primary - INFO - Processing chunk 173/183
2025-05-13 15:26:18,759 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:18,761 - app.services.llm_primary - INFO - Processing chunk 174/183
2025-05-13 15:26:20,909 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:20,910 - app.services.llm_primary - INFO - Processing chunk 175/183
2025-05-13 15:26:23,139 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:23,142 - app.services.llm_primary - INFO - Processing chunk 176/183
2025-05-13 15:26:23,142 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:26:27,243 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:27,247 - app.services.llm_primary - INFO - Processing chunk 177/183
2025-05-13 15:26:28,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:28,693 - app.services.llm_primary - INFO - Processing chunk 178/183
2025-05-13 15:26:31,030 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:31,034 - app.services.llm_primary - INFO - Processing chunk 179/183
2025-05-13 15:26:33,485 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:33,488 - app.services.llm_primary - INFO - Processing chunk 180/183
2025-05-13 15:26:36,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:36,736 - app.services.llm_primary - INFO - Processing chunk 181/183
2025-05-13 15:26:36,736 - app.services.llm_primary - INFO - Taking a short break to avoid rate limits...
2025-05-13 15:26:39,331 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:39,332 - app.services.llm_primary - INFO - Processing chunk 182/183
2025-05-13 15:26:41,783 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:26:41,785 - app.services.llm_primary - INFO - Processing chunk 183/183
2025-05-13 15:26:44,201 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:27:59,919 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-13 15:28:00,261 - app.services.render - INFO - Rendering PDF with WeasyPrint: reports/c65e1b3a-11c3-4ccb-9063-0babf088e39f.pdf
2025-05-13 15:28:00,282 - weasyprint - WARNING - Ignored `box-shadow: 0 0 10px rgba(0,0,0,0.1)` at 14:5, unknown property.
2025-05-13 15:28:00,406 - app.services.render - INFO - PDF generated successfully with WeasyPrint: reports/c65e1b3a-11c3-4ccb-9063-0babf088e39f.pdf
{"timestamp": "2025-05-13T15:28:00.406438", "user_id": 68744272, "chunks": 183, "cost_$": 0.10149999999999999}
2025-05-13 15:28:01,144 - aiogram.event - INFO - Update id=26413145 is handled. Duration 715946 ms by bot id=7216011927
2025-05-13 16:12:14,765 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:12:14,766 - aiogram.dispatcher - WARNING - Sleep for 1.000000 seconds and try again... (tryings = 0, bot id = 7216011927)
2025-05-13 16:12:20,165 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:12:20,165 - aiogram.dispatcher - WARNING - Sleep for 1.242751 seconds and try again... (tryings = 1, bot id = 7216011927)
2025-05-13 16:12:26,045 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:12:26,045 - aiogram.dispatcher - WARNING - Sleep for 1.487051 seconds and try again... (tryings = 2, bot id = 7216011927)
2025-05-13 16:12:32,577 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:12:32,578 - aiogram.dispatcher - WARNING - Sleep for 1.919888 seconds and try again... (tryings = 3, bot id = 7216011927)
2025-05-13 16:12:40,182 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:12:40,183 - aiogram.dispatcher - WARNING - Sleep for 2.481832 seconds and try again... (tryings = 4, bot id = 7216011927)
2025-05-13 16:12:49,116 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:12:49,116 - aiogram.dispatcher - WARNING - Sleep for 3.443490 seconds and try again... (tryings = 5, bot id = 7216011927)
2025-05-13 16:12:57,044 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:12:57,045 - aiogram.dispatcher - WARNING - Sleep for 4.413783 seconds and try again... (tryings = 6, bot id = 7216011927)
2025-05-13 16:13:06,941 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:13:06,941 - aiogram.dispatcher - WARNING - Sleep for 5.254628 seconds and try again... (tryings = 7, bot id = 7216011927)
2025-05-13 16:13:17,888 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:13:17,888 - aiogram.dispatcher - WARNING - Sleep for 5.360689 seconds and try again... (tryings = 8, bot id = 7216011927)
2025-05-13 16:13:28,732 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:13:28,732 - aiogram.dispatcher - WARNING - Sleep for 5.243637 seconds and try again... (tryings = 9, bot id = 7216011927)
2025-05-13 16:13:39,629 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:13:39,630 - aiogram.dispatcher - WARNING - Sleep for 5.090593 seconds and try again... (tryings = 10, bot id = 7216011927)
2025-05-13 16:13:50,159 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:13:50,159 - aiogram.dispatcher - WARNING - Sleep for 5.025155 seconds and try again... (tryings = 11, bot id = 7216011927)
2025-05-13 16:14:00,628 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:14:00,628 - aiogram.dispatcher - WARNING - Sleep for 4.887296 seconds and try again... (tryings = 12, bot id = 7216011927)
2025-05-13 16:14:09,897 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:14:09,898 - aiogram.dispatcher - WARNING - Sleep for 5.172900 seconds and try again... (tryings = 13, bot id = 7216011927)
2025-05-13 16:14:19,733 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:14:19,734 - aiogram.dispatcher - WARNING - Sleep for 5.201877 seconds and try again... (tryings = 14, bot id = 7216011927)
2025-05-13 16:14:30,333 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:14:30,333 - aiogram.dispatcher - WARNING - Sleep for 4.949648 seconds and try again... (tryings = 15, bot id = 7216011927)
2025-05-13 16:14:39,411 - aiogram.dispatcher - ERROR - Failed to fetch updates - TelegramConflictError: Telegram server says - Conflict: terminated by other getUpdates request; make sure that only one bot instance is running
2025-05-13 16:14:39,411 - aiogram.dispatcher - WARNING - Sleep for 4.797198 seconds and try again... (tryings = 16, bot id = 7216011927)
2025-05-13 16:14:48,473 - aiogram.dispatcher - WARNING - Received SIGTERM signal
2025-05-13 16:14:48,474 - aiogram.dispatcher - INFO - Polling stopped for bot @emotionalanalbot id=7216011927 - 'emotionalanal'
2025-05-13 16:14:48,474 - aiogram.dispatcher - INFO - Polling stopped
