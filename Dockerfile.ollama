# Dockerfile.ollama â€“ image for private Ollama Llama service on Render
FROM ollama/ollama:latest

# Set environment variables
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_ORIGINS=*

# Create startup script
RUN echo '#!/bin/bash\n\
echo "Starting Ollama service..."\n\
echo "Pulling llama2:7b-chat model..."\n\
ollama pull llama2:7b-chat\n\
echo "Starting Ollama server..."\n\
exec ollama serve\n' > /start.sh && chmod +x /start.sh

# Expose the Ollama API port
EXPOSE 11434

# Start Ollama with the startup script
CMD ["/start.sh"] 