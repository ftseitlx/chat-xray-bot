# Dockerfile.ollama â€“ image for private Ollama Llama service on Render
FROM ollama/ollama:latest

# Set environment variables
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_ORIGINS=*

# Create startup script
RUN echo '#!/bin/bash\n\
echo "Starting Ollama service..."\n\
\n\
# Start Ollama server\n\
echo "Starting Ollama server..."\n\
ollama serve &\n\
\n\
# Wait for server to be ready\n\
echo "Waiting for Ollama server to be ready..."\n\
sleep 10\n\
\n\
# Pull model\n\
echo "Pulling llama2:7b-chat model..."\n\
ollama pull llama2:7b-chat\n\
\n\
# Keep container running\n\
wait\n' > /start.sh && chmod +x /start.sh

# Expose the Ollama API port
EXPOSE 11434

# Start Ollama with the startup script
CMD ["/start.sh"] 